{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "deJX27tw7JMN",
        "colab_type": "text"
      },
      "source": [
        "Firstly, we are importing numpy and tensorflow for the implementation purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfTDdmfaz_RS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUL7jJUI7tQS",
        "colab_type": "text"
      },
      "source": [
        "Next, We are downloading the datasets from the github and storing the data in the Colab's internal storage by making a folder named 'data'. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrz1P1Uv3pDu",
        "colab_type": "code",
        "outputId": "b6b96dcd-c843-41e4-e045-87f6527087de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "!mkdir data\n",
        "#https://github.com/agungsantoso/deep-learning-v2-pytorch/raw/master/sentiment-rnn/data/labels.txt\n",
        "!wget -c https://github.com/mchablani/deep-learning/raw/master/sentiment-network/reviews.txt\n",
        "!wget -c https://github.com/mchablani/deep-learning/raw/master/sentiment-network/labels.txt\n",
        "!mv *.txt data/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2019-06-08 10:32:21--  https://github.com/mchablani/deep-learning/raw/master/sentiment-network/reviews.txt\n",
            "Resolving github.com (github.com)... 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mchablani/deep-learning/master/sentiment-network/reviews.txt [following]\n",
            "--2019-06-08 10:32:21--  https://raw.githubusercontent.com/mchablani/deep-learning/master/sentiment-network/reviews.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33678267 (32M) [text/plain]\n",
            "Saving to: ‘reviews.txt’\n",
            "\n",
            "reviews.txt         100%[===================>]  32.12M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2019-06-08 10:32:22 (223 MB/s) - ‘reviews.txt’ saved [33678267/33678267]\n",
            "\n",
            "--2019-06-08 10:32:25--  https://github.com/mchablani/deep-learning/raw/master/sentiment-network/labels.txt\n",
            "Resolving github.com (github.com)... 192.30.253.112\n",
            "Connecting to github.com (github.com)|192.30.253.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/mchablani/deep-learning/master/sentiment-network/labels.txt [following]\n",
            "--2019-06-08 10:32:25--  https://raw.githubusercontent.com/mchablani/deep-learning/master/sentiment-network/labels.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 225000 (220K) [text/plain]\n",
            "Saving to: ‘labels.txt’\n",
            "\n",
            "labels.txt          100%[===================>] 219.73K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2019-06-08 10:32:26 (7.75 MB/s) - ‘labels.txt’ saved [225000/225000]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A3O5D6ltmck",
        "colab_type": "text"
      },
      "source": [
        "We are here opening the text data, which are two files, one is called 'reviews', which contains the raw data of meaning reviews of movies, which includes blank space, very very long sized reviews, even some very short ones. Another one is labels, which indicates, if the review is positive or negative. The reviews and labels are length of 25001."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N34Ye4sSY4N_",
        "colab_type": "code",
        "outputId": "fe54cf8e-1c44-4a18-e339-de615f627038",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# open text file and read in data as `text`\n",
        "with open('data/reviews.txt', 'r') as f:\n",
        "    reviews = f.read()\n",
        "with open('data/labels.txt', 'r') as f:\n",
        "    labels = f.read()\n",
        "    \n",
        "print(reviews[:2000])\n",
        "print()\n",
        "print(labels[:26])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   \n",
            "story of a man who has unnatural feelings for a pig . starts out with a opening scene that is a terrific example of absurd comedy . a formal orchestra audience is turned into an insane  violent mob by the crazy chantings of it  s singers . unfortunately it stays absurd the whole time with no general narrative eventually making it just too off putting . even those from the era should be turned off . the cryptic dialogue would make shakespeare seem easy to a third grader . on a technical level it  s better than you might think with some good cinematography by future great vilmos zsigmond . future stars sally kirkland and frederic forrest can be seen briefly .  \n",
            "homelessness  or houselessness as george carlin stated  has been an issue for years but never a plan to help those on the street that were once considered human who did everything from going to school  work  or vote for the matter . most people think of the homeless as just a lost cause while worrying about things such as racism  the war on iraq  pressuring kids to succeed  technology  the elections  inflation  or worrying if they  ll be next to end up on the streets .  br    br   but what if y\n",
            "\n",
            "positive\n",
            "negative\n",
            "positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36HOk2g811bw",
        "colab_type": "text"
      },
      "source": [
        "Now we will to make our data, which is Movie Reviews, feedable into our Model. That is why we need to pre-process the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vqTE2IekOhe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#reviews = reviews.split()\n",
        "#print(reviews[:200])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXRun8c81rdo",
        "colab_type": "text"
      },
      "source": [
        "We are going to do the first pre-processing step of our Movie Reviews data, which is to make any text in lower form, which are in the capital form. We will do it using `.lower()` function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43-FHUxana83",
        "colab_type": "code",
        "outputId": "38f6e0dc-4970-435e-e044-077e658f8a9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "reviews = reviews.lower()\n",
        "\n",
        "print(reviews[:200])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hT41UFY43_AA",
        "colab_type": "text"
      },
      "source": [
        "Next pre-processing step is to remove any punctuations like `!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~`. For that, we are just importing punctuations function from string and removing it the later part using a for loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AKjr_sx-wu6A",
        "colab_type": "code",
        "outputId": "8ece377e-c305-4966-d08f-6157b3882092",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "from string import punctuation\n",
        "print(punctuation)\n",
        "\n",
        "all_text = ''.join([c for c in reviews if c not in punctuation])\n",
        "print(all_text[:200])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
            "bromwell high is a cartoon comedy  it ran at the same time as some other programs about school life  such as  teachers   my   years in the teaching profession lead me to believe that bromwell high  s \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIVUs4cF5yJ8",
        "colab_type": "text"
      },
      "source": [
        "Then we are spliting the reviews in a single single manner. Before this step, all the reviews were messed up in a single line form, which is very confusing for a computer to read. We are also printing the number of total reviews, which is 25,001 here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSvQrDqM0k3i",
        "colab_type": "code",
        "outputId": "0a74047f-0d52-4ab0-9a01-4f1e44dd84cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "reviews_split = all_text.split('\\n')\n",
        "print(\"Number of Reviews: \", len(reviews_split))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Reviews:  25001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W5RdKH236R0W",
        "colab_type": "text"
      },
      "source": [
        "We are again doing it for the labels part."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvskEFFKzuXJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels_split = labels.split('\\n')\n",
        "print(labels_split)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5QnZbiru7iVt",
        "colab_type": "text"
      },
      "source": [
        "Here, we are Tokenizing our input words. First, we are making our words separate from our sentences. Then counting the word sequence, means which word used how many time and arranges them according to the descending order. \n",
        "As you can see that word **'the'** used most times, **336713** times.\n",
        "I am also printing the total number we can find here, which is 6020196."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wqn0qYGUImnY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter\n",
        "counter_words = ''.join(reviews_split)\n",
        "\n",
        "words = counter_words.split()\n",
        "\n",
        "counter = Counter(words)\n",
        "print(counter)\n",
        "\n",
        "total_words = len(words)\n",
        "print(total_words)\n",
        "sorted_words = counter.most_common(total_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anpS3AIL9TQL",
        "colab_type": "text"
      },
      "source": [
        "Here, we are creating a voacb to index mapping dictionary in such a way that your frequently occurring words are assigned lower indexes. \n",
        "\n",
        "\n",
        " There is a little trick here, in this mapping index will start from 0 i.e. mapping of ‘the’ will be 0. But later on we are going to do padding for shorter reviews and conventional choice for padding is 0. So we need to start this indexing from 1.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKi49zQ1pI34",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_to_int = {w:i+1 for i, (w,c) in enumerate(sorted_words)}\n",
        "print(vocab_to_int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uyuek_4z_M-v",
        "colab_type": "text"
      },
      "source": [
        "In this stage we will encode the input reviews. We did make a list of single single reviews, made the index-mapping dictionary and now we will, make the proper word to integer encoding, i.e. replace words in our reviews by integers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRD4Q9EhiLvN",
        "colab_type": "code",
        "outputId": "321809ec-3c1d-4d86-93c1-69daf5e7e8f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "reviews_int = []\n",
        "for review in reviews_split:\n",
        "  r = [vocab_to_int[w] for w in review.split()]\n",
        "  reviews_int.append(r)\n",
        "print(reviews_int[0:3])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[21025, 308, 6, 3, 1050, 207, 8, 2138, 32, 1, 171, 57, 15, 49, 81, 5785, 44, 382, 110, 140, 15, 5194, 60, 154, 9, 1, 4975, 5852, 475, 71, 5, 260, 12, 21025, 308, 13, 1978, 6, 74, 2395, 5, 613, 73, 6, 5194, 1, 24103, 5, 1983, 10166, 1, 5786, 1499, 36, 51, 66, 204, 145, 67, 1199, 5194, 19869, 1, 37442, 4, 1, 221, 883, 31, 2988, 71, 4, 1, 5787, 10, 686, 2, 67, 1499, 54, 10, 216, 1, 383, 9, 62, 3, 1406, 3686, 783, 5, 3483, 180, 1, 382, 10, 1212, 13583, 32, 308, 3, 349, 341, 2913, 10, 143, 127, 5, 7690, 30, 4, 129, 5194, 1406, 2326, 5, 21025, 308, 10, 528, 12, 109, 1448, 4, 60, 543, 102, 12, 21025, 308, 6, 227, 4146, 48, 3, 2211, 12, 8, 215, 23], [63, 4, 3, 125, 36, 47, 7472, 1395, 16, 3, 4181, 505, 45, 17, 3, 622, 134, 12, 6, 3, 1279, 457, 4, 1721, 207, 3, 10624, 7373, 300, 6, 667, 83, 35, 2116, 1086, 2989, 34, 1, 898, 46417, 4, 8, 13, 5096, 464, 8, 2656, 1721, 1, 221, 57, 17, 58, 794, 1297, 832, 228, 8, 43, 98, 123, 1469, 59, 147, 38, 1, 963, 142, 29, 667, 123, 1, 13584, 410, 61, 94, 1774, 306, 755, 5, 3, 819, 10396, 22, 3, 1724, 635, 8, 13, 128, 73, 21, 233, 102, 17, 49, 50, 617, 34, 682, 85, 28785, 28786, 682, 374, 3341, 11398, 2, 16371, 7946, 51, 29, 108, 3324], [22382, 42, 46418, 15, 706, 17139, 3389, 47, 77, 35, 1819, 16, 154, 19, 114, 3, 1305, 5, 336, 147, 22, 1, 857, 12, 70, 281, 1168, 399, 36, 120, 283, 38, 169, 5, 382, 158, 42, 2269, 16, 1, 541, 90, 78, 102, 4, 1, 3244, 15, 43, 3, 407, 1068, 136, 8055, 44, 182, 140, 15, 3043, 1, 320, 22, 4818, 26224, 346, 5, 3090, 2092, 1, 18839, 17939, 42, 8055, 46, 33, 236, 29, 370, 5, 130, 56, 22, 1, 1928, 7, 7, 19, 48, 46, 21, 70, 344, 3, 2099, 5, 408, 22, 1, 1928, 16, 3, 3119, 205, 1, 28787, 21, 281, 68, 38, 3, 339, 1, 700, 715, 3, 3818, 1229, 22, 1, 1491, 3, 1197, 2, 283, 21, 281, 2435, 5, 66, 48, 8, 13, 39, 5, 29, 3244, 12, 6, 21026, 11723, 13, 2015, 7, 7, 3687, 2818, 36, 4147, 36, 374, 15, 11723, 296, 3, 996, 125, 36, 47, 283, 9, 1, 176, 363, 6893, 5, 94, 3, 2099, 17, 3, 4976, 2932, 14557, 19870, 5, 66, 46, 25, 51, 408, 9, 1, 1928, 16, 3236, 490, 205, 1, 28787, 46, 11723, 2845, 25, 51, 80, 48, 25, 483, 17, 3, 682, 1148, 4, 228, 52, 4461, 1, 2099, 13, 22, 118, 11723, 6, 1347, 22, 1, 857, 17, 3, 18840, 22, 27, 3873, 5, 10167, 27, 174, 829, 118, 25, 51, 23, 1456, 123, 1, 6451, 25, 13, 344, 1, 13585, 28788, 34, 3, 32300, 101, 8, 13, 391, 22, 27, 11724, 118, 11723, 874, 81, 103, 577, 3, 240, 34, 1, 393, 4, 4653, 16372, 1816, 3737, 35, 1200, 3103, 36, 188, 4048, 160, 2284, 41, 339, 2, 41, 8809, 6793, 1984, 4313, 2, 28789, 8810, 2457, 36, 26, 453, 338, 5, 1, 1928, 33, 155, 4219, 11723, 215, 23, 25, 13, 24, 338, 5, 4421, 5903, 28790, 39, 25, 281, 120, 54, 111, 996, 118, 8, 13, 534, 42, 2718, 501, 42, 29, 547, 7, 7, 136, 1, 115, 2003, 198, 4653, 2, 11723, 285, 23, 1644, 5, 112, 10, 254, 110, 4354, 5, 29, 30, 4, 3687, 2818, 15686, 107, 118, 2523, 5, 111, 3, 207, 8, 286, 3, 4220, 488, 1060, 5, 27, 2730, 158, 140, 15, 7473, 11399, 184, 4539, 42, 18841, 16, 1, 541, 5, 121, 48, 8, 13, 39, 255, 141, 4504, 160, 2284, 8, 1, 370, 245, 42, 22, 1, 81, 495, 228, 3, 372, 2099, 39, 31, 996, 78, 80, 54, 33, 89, 23, 122, 48, 5, 80, 17, 67, 273, 277, 33, 142, 200, 8, 5, 1, 3244, 303, 4, 757, 8, 39, 17140, 273, 7, 7, 42, 277, 11, 20, 79, 5853, 21, 5, 336, 400]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5JOcwzAAhHO",
        "colab_type": "text"
      },
      "source": [
        "We will do it for the labels too along with reviews."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "za5orodzyFXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoded_labels = [1 if labels == \"positive\" else 0 for labels in labels_split]\n",
        "encoded_labels = np.array(encoded_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9zFgS5b84Rkz",
        "colab_type": "code",
        "outputId": "ff259867-d2cf-466b-e337-ce7427941e9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "reviews_len = [len(x) for x in reviews_int]\n",
        "pd.Series(reviews_len).hist()\n",
        "plt.show()\n",
        "pd.Series(reviews_len).describe()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAD9CAYAAABX0LttAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ns4zDwczMMv8fwvQmNqHaUcoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    25001.000000\n",
              "mean       240.798208\n",
              "std        179.020628\n",
              "min          0.000000\n",
              "25%        130.000000\n",
              "50%        179.000000\n",
              "75%        293.000000\n",
              "max       2514.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdlVU2uuCB33",
        "colab_type": "text"
      },
      "source": [
        "We will remove outliers from the review sets. Outlier means reviews which is too short like 0 words or so."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97cR0xhpCm6y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_int = [reviews_int[i] for i, l in enumerate(reviews_len) if l > 0]\n",
        "encoded_labels = [encoded_labels[i] for i, l in enumerate(reviews_len) if l > 0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnZf9gPuCYIU",
        "colab_type": "text"
      },
      "source": [
        "We have to set a sequence length, in which the reviews are going to lie. Reviews, which are larger than sequence length, we will truncate them and reviews, which are less than sequence length, we will pad them using zeros."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWa558JTTdlB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_features(reviews_int, sequence_length):\n",
        "  \n",
        "  features = np.zeros((len(reviews_int), sequence_length), dtype = int)\n",
        "  \n",
        "  for i, review in enumerate(reviews_int):\n",
        "    \n",
        "    reviews_len = len(review)\n",
        "    \n",
        "    if reviews_len <= sequence_length:\n",
        "      zeroes = list(np.zeros(sequence_length - reviews_len))\n",
        "      new = zeroes + review\n",
        "      \n",
        "    elif reviews_len > sequence_length:\n",
        "      new = review[0:sequence_length]\n",
        "      \n",
        "    features[i, :] = np.array(new)\n",
        "    \n",
        "  return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCQTQwvbJlan",
        "colab_type": "code",
        "outputId": "f78b43f9-c5dd-4d83-e726-387193cc8ad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "sequence_length = 100\n",
        "\n",
        "features = pad_features(reviews_int, sequence_length = sequence_length)\n",
        "\n",
        "#assert len(features)==len(reviews_int)\n",
        "#assert len(features[0])==sequence_length\n",
        "\n",
        "print (features[:10,:10])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[21025   308     6     3  1050   207     8  2138    32     1]\n",
            " [   63     4     3   125    36    47  7472  1395    16     3]\n",
            " [22382    42 46418    15   706 17139  3389    47    77    35]\n",
            " [ 4505   505    15     3  3342   162  8312  1652     6  4819]\n",
            " [  520   119   113    34 16372  1816  3737   117   885 21030]\n",
            " [   11    20  3637   141    10   422    23   272    60  4355]\n",
            " [   11     6   692     1    90  2156    20 11728     1  2818]\n",
            " [  786   295    10   122    11     6   419     5    29    35]\n",
            " [   11     6    24     1   779  3687  2818    20     8    14]\n",
            " [   54    10    14   116    60   798   552    71   364     5]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jVHiJFtGO1-a",
        "colab_type": "code",
        "outputId": "941b0b7a-58ed-4809-ebee-a306792778ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "split_frac = 0.85\n",
        "\n",
        "split_num = int(len(features) * split_frac)\n",
        "train_x, remaining_x = features[0:split_num], features[split_num:]\n",
        "train_y, remaining_y = encoded_labels[0:split_num], encoded_labels[split_num:]\n",
        "\n",
        "remain = int(len(remaining_x) * 0.5)\n",
        "valid_x, test_x = remaining_x[:remain], remaining_x[remain:]\n",
        "valid_y, test_y = remaining_y[:remain], remaining_y[remain:]\n",
        "\n",
        "print('shape of training set: {}' .format(train_x.shape))\n",
        "print('shape of valid set: {}' .format(valid_x.shape))\n",
        "print('shape of test set: {}' .format(test_x.shape))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "shape of training set: (21250, 100)\n",
            "shape of valid set: (1875, 100)\n",
            "shape of test set: (1875, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENhCFzs2eB3R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "train_data = TensorDataset(torch.from_numpy(np.array(train_x)), torch.from_numpy(np.array(train_y)))\n",
        "valid_data = TensorDataset(torch.from_numpy(np.array(valid_x)), torch.from_numpy(np.array(valid_y)))\n",
        "test_data = TensorDataset(torch.from_numpy(np.array(test_x)), torch.from_numpy(np.array(test_y)))\n",
        "\n",
        "batch_size = 25\n",
        "\n",
        "dataloader_train = DataLoader(train_data, shuffle = True, batch_size = batch_size)\n",
        "dataloader_valid = DataLoader(valid_data, shuffle = True, batch_size = batch_size)\n",
        "dataloader_test = DataLoader(test_data, shuffle = True, batch_size = batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XK7ccPghRVrZ",
        "colab_type": "code",
        "outputId": "4d859287-358c-4566-b928-d7ff025a1c41",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "dataiter = iter(dataloader_train)\n",
        "sample_x, sample_y = dataiter.next()\n",
        "\n",
        "print('the size of the input: {}' .format(sample_x.shape))\n",
        "print()\n",
        "print('The input sample {}' .format(sample_x))\n",
        "print()\n",
        "print('The Test Sample {}' .format(sample_y))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "the size of the input: torch.Size([25, 100])\n",
            "\n",
            "The input sample tensor([[   10,   195,    11,  ...,    16,    21,    21],\n",
            "        [  256,    24,     1,  ...,   285,    23,  2636],\n",
            "        [   11,    20,     6,  ...,     9,     1,    63],\n",
            "        ...,\n",
            "        [  148,  1090,   692,  ...,     1,   212, 58697],\n",
            "        [   11,     6,    30,  ...,   125,    17,  4326],\n",
            "        [ 6216,     4,    31,  ...,     7,     7,    87]])\n",
            "\n",
            "The Test Sample tensor([1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
            "        0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m19hlR1assX7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "class SentimentLSTM(nn.Module):\n",
        "    \"\"\"\n",
        "    The RNN model that will be used to perform Sentiment analysis.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, vocab_size, output_size, embedding_dim, hidden_dim, n_layers, drop_prob=0.5):\n",
        "        \"\"\"\n",
        "        Initialize the model by setting up the layers.\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "\n",
        "        self.output_size = output_size\n",
        "        self.n_layers = n_layers\n",
        "        self.hidden_dim = hidden_dim\n",
        "        \n",
        "        # embedding and LSTM layers\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, n_layers, \n",
        "                            dropout=drop_prob, batch_first=True)\n",
        "        \n",
        "        # dropout layer\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        \n",
        "        # linear and sigmoid layers\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        \n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        \"\"\"\n",
        "        Perform a forward pass of our model on some input and hidden state.\n",
        "        \"\"\"\n",
        "        batch_size = x.size(0)\n",
        "\n",
        "        # embeddings and lstm_out\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, hidden = self.lstm(embeds, hidden)\n",
        "    \n",
        "        # stack up lstm outputs\n",
        "        lstm_out = lstm_out.contiguous().view(-1, self.hidden_dim)\n",
        "        \n",
        "        # dropout and fully-connected layer\n",
        "        out = self.dropout(lstm_out)\n",
        "        out = self.fc(out)\n",
        "        # sigmoid function\n",
        "        sig_out = self.sig(out)\n",
        "        \n",
        "        # reshape to be batch_size first\n",
        "        sig_out = sig_out.view(batch_size, -1)\n",
        "        sig_out = sig_out[:, -1] # get last batch of labels\n",
        "        \n",
        "        # return last sigmoid output and hidden state\n",
        "        return sig_out, hidden\n",
        "    \n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        ''' Initializes hidden state '''\n",
        "        # Create two new tensors with sizes n_layers x batch_size x hidden_dim,\n",
        "        # initialized to zero, for hidden state and cell state of LSTM\n",
        "        weight = next(self.parameters()).data\n",
        "        \n",
        "        if (train_on_gpu):\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda(),\n",
        "                  weight.new(self.n_layers, batch_size, self.hidden_dim).zero_().cuda())\n",
        "        else:\n",
        "            hidden = (weight.new(self.n_layers, batch_size, self.hidden_dim).zero_(),\n",
        "                      weight.new(self.n_layers, batch_size, self.hidden_dim).zero_())\n",
        "        \n",
        "        return hidden"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdvEAtVb5C_1",
        "colab_type": "code",
        "outputId": "138df955-f931-4e5e-dbcd-41ff81effe44",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "# Instantiate the model w/ hyperparams\n",
        "vocab_size = len(vocab_to_int)+1 # +1 for the 0 padding\n",
        "output_size = 1\n",
        "embedding_dim = 400\n",
        "hidden_dim = 256\n",
        "n_layers = 2\n",
        "\n",
        "net = SentimentLSTM(vocab_size, output_size, embedding_dim, hidden_dim, n_layers)\n",
        "\n",
        "print(net)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "SentimentLSTM(\n",
            "  (embedding): Embedding(74073, 400)\n",
            "  (lstm): LSTM(400, 256, num_layers=2, batch_first=True, dropout=0.5)\n",
            "  (dropout): Dropout(p=0.3)\n",
            "  (fc): Linear(in_features=256, out_features=1, bias=True)\n",
            "  (sig): Sigmoid()\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XN0aHBY81ex7",
        "colab_type": "code",
        "outputId": "b149aff6-666a-4f68-a014-48debd936d54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# check if CUDA is available\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "    print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "    print('CUDA is available!  Training on GPU ...')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uGm7INsi6O37",
        "colab_type": "code",
        "outputId": "76abe807-846b-4a56-de52-c3bd1d59b3a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWSxv6iA4IAd",
        "colab_type": "code",
        "outputId": "60faab03-c747-463c-da25-316af7298515",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# loss and optimization functions\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
        "\n",
        "net = net.to(device)\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bZv-FrgEIHZ",
        "colab_type": "code",
        "outputId": "e6992788-9768-4fb2-8127-e8e0d1f8ebd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 731
        }
      },
      "source": [
        "# training params\n",
        "\n",
        "epochs = 5 # 3-4 is approx where I noticed the validation loss stop decreasing\n",
        "\n",
        "counter = 0\n",
        "print_every = 100\n",
        "clip=5 # gradient clipping\n",
        "\n",
        "# move model to GPU, if available\n",
        "#if(train_on_gpu):\n",
        "#    net.cuda()\n",
        "    \n",
        "net.train()\n",
        "# train for some number of epochs\n",
        "for e in range(epochs):\n",
        "    \n",
        "    # initialize hidden state\n",
        "    h = net.init_hidden(batch_size)\n",
        "\n",
        "    # batch loop\n",
        "    for inputs, labels in dataloader_train:\n",
        "        counter += 1\n",
        "\n",
        "        #if(train_on_gpu):\n",
        "         #   inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        # Creating new variables for the hidden state, otherwise\n",
        "        # we'd backprop through the entire training history\n",
        "        h = tuple([each.data for each in h])\n",
        "\n",
        "        # zero accumulated gradients\n",
        "        net.zero_grad()\n",
        "\n",
        "        # get the output from the model\n",
        "        output, h = net(inputs, h)\n",
        "\n",
        "        # calculate the loss and perform backprop\n",
        "        loss = criterion(output.squeeze(), labels.float())\n",
        "        loss.backward()\n",
        "        # `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.\n",
        "        nn.utils.clip_grad_norm_(net.parameters(), clip)\n",
        "        optimizer.step()\n",
        "\n",
        "        # loss stats\n",
        "        if counter % print_every == 0:\n",
        "            # Get validation loss\n",
        "            val_h = net.init_hidden(batch_size)\n",
        "            val_losses = []\n",
        "            net.eval()\n",
        "            for inputs, labels in dataloader_valid:\n",
        "\n",
        "                # Creating new variables for the hidden state, otherwise\n",
        "                # we'd backprop through the entire training history\n",
        "                val_h = tuple([each.data for each in val_h])\n",
        "\n",
        "                #if(train_on_gpu):\n",
        "                #    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "                inputs, labels = inputs.to(device), labels.to(device)\n",
        "                \n",
        "                output, val_h = net(inputs, val_h)\n",
        "                val_loss = criterion(output.squeeze(), labels.float())\n",
        "\n",
        "                val_losses.append(val_loss.item())\n",
        "\n",
        "            net.train()\n",
        "            print(\"Epoch: {}/{}...\".format(e+1, epochs),\n",
        "                  \"Step: {}...\".format(counter),\n",
        "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
        "                  \"Val Loss: {:.6f}\".format(np.mean(val_losses)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 1/5... Step: 100... Loss: 0.697688... Val Loss: 0.692487\n",
            "Epoch: 1/5... Step: 200... Loss: 0.690286... Val Loss: 0.691873\n",
            "Epoch: 1/5... Step: 300... Loss: 0.704755... Val Loss: 0.690212\n",
            "Epoch: 1/5... Step: 400... Loss: 0.673727... Val Loss: 0.670775\n",
            "Epoch: 1/5... Step: 500... Loss: 0.817910... Val Loss: 0.714557\n",
            "Epoch: 1/5... Step: 600... Loss: 0.555450... Val Loss: 0.589318\n",
            "Epoch: 1/5... Step: 700... Loss: 0.548932... Val Loss: 0.579530\n",
            "Epoch: 1/5... Step: 800... Loss: 0.511023... Val Loss: 0.554922\n",
            "Epoch: 2/5... Step: 900... Loss: 0.461807... Val Loss: 0.555534\n",
            "Epoch: 2/5... Step: 1000... Loss: 0.594699... Val Loss: 0.548774\n",
            "Epoch: 2/5... Step: 1100... Loss: 0.519049... Val Loss: 0.553135\n",
            "Epoch: 2/5... Step: 1200... Loss: 0.587282... Val Loss: 0.504896\n",
            "Epoch: 2/5... Step: 1300... Loss: 0.519955... Val Loss: 0.505637\n",
            "Epoch: 2/5... Step: 1400... Loss: 0.590332... Val Loss: 0.535811\n",
            "Epoch: 2/5... Step: 1500... Loss: 0.552583... Val Loss: 0.527420\n",
            "Epoch: 2/5... Step: 1600... Loss: 0.609636... Val Loss: 0.495255\n",
            "Epoch: 2/5... Step: 1700... Loss: 0.674547... Val Loss: 0.482581\n",
            "Epoch: 3/5... Step: 1800... Loss: 0.472905... Val Loss: 0.476415\n",
            "Epoch: 3/5... Step: 1900... Loss: 0.379928... Val Loss: 0.490844\n",
            "Epoch: 3/5... Step: 2000... Loss: 0.347360... Val Loss: 0.527470\n",
            "Epoch: 3/5... Step: 2100... Loss: 0.428487... Val Loss: 0.483448\n",
            "Epoch: 3/5... Step: 2200... Loss: 0.281323... Val Loss: 0.474702\n",
            "Epoch: 3/5... Step: 2300... Loss: 0.495370... Val Loss: 0.554248\n",
            "Epoch: 3/5... Step: 2400... Loss: 0.371529... Val Loss: 0.487433\n",
            "Epoch: 3/5... Step: 2500... Loss: 0.437922... Val Loss: 0.480137\n",
            "Epoch: 4/5... Step: 2600... Loss: 0.089657... Val Loss: 0.507237\n",
            "Epoch: 4/5... Step: 2700... Loss: 0.580959... Val Loss: 0.541294\n",
            "Epoch: 4/5... Step: 2800... Loss: 0.224582... Val Loss: 0.525359\n",
            "Epoch: 4/5... Step: 2900... Loss: 0.215687... Val Loss: 0.480450\n",
            "Epoch: 4/5... Step: 3000... Loss: 0.267068... Val Loss: 0.488482\n",
            "Epoch: 4/5... Step: 3100... Loss: 0.175071... Val Loss: 0.502367\n",
            "Epoch: 4/5... Step: 3200... Loss: 0.223692... Val Loss: 0.498334\n",
            "Epoch: 4/5... Step: 3300... Loss: 0.338221... Val Loss: 0.465687\n",
            "Epoch: 4/5... Step: 3400... Loss: 0.382802... Val Loss: 0.481313\n",
            "Epoch: 5/5... Step: 3500... Loss: 0.384592... Val Loss: 0.523095\n",
            "Epoch: 5/5... Step: 3600... Loss: 0.223163... Val Loss: 0.524477\n",
            "Epoch: 5/5... Step: 3700... Loss: 0.196929... Val Loss: 0.556029\n",
            "Epoch: 5/5... Step: 3800... Loss: 0.241876... Val Loss: 0.510804\n",
            "Epoch: 5/5... Step: 3900... Loss: 0.182217... Val Loss: 0.519470\n",
            "Epoch: 5/5... Step: 4000... Loss: 0.312246... Val Loss: 0.513453\n",
            "Epoch: 5/5... Step: 4100... Loss: 0.115358... Val Loss: 0.509224\n",
            "Epoch: 5/5... Step: 4200... Loss: 0.092118... Val Loss: 0.503475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4QEvI8n5A--",
        "colab_type": "code",
        "outputId": "848ac3e9-b194-4cdb-9b6f-9b0b435547cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Get test data loss and accuracy\n",
        "\n",
        "test_losses = [] # track loss\n",
        "num_correct = 0\n",
        "\n",
        "# init hidden state\n",
        "h = net.init_hidden(batch_size)\n",
        "\n",
        "net.eval()\n",
        "# iterate over test data\n",
        "for inputs, labels in dataloader_test:\n",
        "\n",
        "    # Creating new variables for the hidden state, otherwise\n",
        "    # we'd backprop through the entire training history\n",
        "    h = tuple([each.data for each in h])\n",
        "\n",
        "    #if(train_on_gpu):\n",
        "    #    inputs, labels = inputs.cuda(), labels.cuda()\n",
        "    \n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    \n",
        "    # get predicted outputs\n",
        "    #inputs = inputs.type(torch.LongTensor)\n",
        "    output, h = net(inputs, h)\n",
        "    \n",
        "    # calculate loss\n",
        "    test_loss = criterion(output.squeeze(), labels.float())\n",
        "    test_losses.append(test_loss.item())\n",
        "    \n",
        "    # convert output probabilities to predicted class (0 or 1)\n",
        "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
        "    \n",
        "    # compare predictions to true label\n",
        "    correct_tensor = pred.eq(labels.float().view_as(pred))\n",
        "    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n",
        "    num_correct += np.sum(correct)\n",
        "\n",
        "\n",
        "# -- stats! -- ##\n",
        "# avg test loss\n",
        "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
        "\n",
        "# accuracy over all test data\n",
        "test_acc = num_correct/len(dataloader_test.dataset)\n",
        "print(\"Test accuracy: {:.3f}\".format(test_acc))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.532\n",
            "Test accuracy: 0.785\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}